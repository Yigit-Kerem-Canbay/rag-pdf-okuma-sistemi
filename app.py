import os
import re
import uuid
from pathlib import Path
from typing import Dict, List, Tuple

import chromadb
from chromadb import errors as chroma_errors
from chromadb.config import Settings
from dotenv import load_dotenv
import google.generativeai as genai
import gradio as gr
import requests
from pypdf import PdfReader
from sentence_transformers import SentenceTransformer

# Groq API iÃ§in (opsiyonel)
try:
    from groq import Groq
    GROQ_AVAILABLE = True
except ImportError:
    GROQ_AVAILABLE = False


load_dotenv()

EMBED_MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
CHUNK_SIZE = 1000
CHUNK_OVERLAP = 150
DEFAULT_TOP_K = 4
MMR_LAMBDA = 0.5
COLLECTION_NAME = "active_pdf"
DEFAULT_CITY = "ElazÄ±ÄŸ"

# TÃ¼rkiye'nin 81 ÅŸehri (alfabetik sÄ±ralÄ±)
TURKIYE_SEHIRLERI = [
    "Adana", "AdÄ±yaman", "Afyonkarahisar", "AÄŸrÄ±", "Aksaray", "Amasya", "Ankara", "Antalya",
    "Ardahan", "Artvin", "AydÄ±n", "BalÄ±kesir", "BartÄ±n", "Batman", "Bayburt", "Bilecik",
    "BingÃ¶l", "Bitlis", "Bolu", "Burdur", "Bursa", "Ã‡anakkale", "Ã‡ankÄ±rÄ±", "Ã‡orum",
    "Denizli", "DiyarbakÄ±r", "DÃ¼zce", "Edirne", "ElazÄ±ÄŸ", "Erzincan", "Erzurum", "EskiÅŸehir",
    "Gaziantep", "Giresun", "GÃ¼mÃ¼ÅŸhane", "Hakkari", "Hatay", "IÄŸdÄ±r", "Isparta", "Ä°stanbul",
    "Ä°zmir", "KahramanmaraÅŸ", "KarabÃ¼k", "Karaman", "Kars", "Kastamonu", "Kayseri", "KÄ±rÄ±kkale",
    "KÄ±rklareli", "KÄ±rÅŸehir", "Kilis", "Kocaeli", "Konya", "KÃ¼tahya", "Malatya", "Manisa",
    "Mardin", "Mersin", "MuÄŸla", "MuÅŸ", "NevÅŸehir", "NiÄŸde", "Ordu", "Osmaniye", "Rize",
    "Sakarya", "Samsun", "ÅanlÄ±urfa", "Siirt", "Sinop", "ÅÄ±rnak", "Sivas", "TekirdaÄŸ",
    "Tokat", "Trabzon", "Tunceli", "UÅŸak", "Van", "Yalova", "Yozgat", "Zonguldak"
]

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
WEATHER_API_KEY = os.getenv("WEATHER_API_KEY")

if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)

_gemini_model = None


def list_available_models():
    """KullanÄ±labilir Gemini modellerini listeler"""
    try:
        models = genai.list_models()
        available = [m.name for m in models if 'generateContent' in m.supported_generation_methods]
        return available
    except Exception:
        return []


def get_gemini_model():
    global _gemini_model
    if not GOOGLE_API_KEY:
        raise RuntimeError(
            "GOOGLE_API_KEY deÄŸerini .env dosyasÄ±na ekleyip uygulamayÄ± yeniden baÅŸlatÄ±n."
        )
    if _gemini_model is None:
        # Mevcut modeller: Ã¶nce en gÃ¼ncel ve hÄ±zlÄ± olanlarÄ± dene
        model_candidates = [
            "gemini-2.5-flash",      # En gÃ¼ncel flash model (hÄ±zlÄ±)
            "gemini-flash-latest",   # Her zaman en gÃ¼ncel flash
            "gemini-2.5-pro",        # GÃ¼Ã§lÃ¼ ama daha yavaÅŸ
            "gemini-pro-latest",     # Her zaman en gÃ¼ncel pro
            "gemini-1.5-flash",      # Eski ama stabil
            "gemini-1.5-pro",        # Eski ama stabil
        ]
        
        for model_name in model_candidates:
            try:
                _gemini_model = genai.GenerativeModel(model_name)
                # Model baÅŸarÄ±yla oluÅŸturuldu
                break
            except Exception:
                continue
        
        if _gemini_model is None:
            # Son Ã§are: kullanÄ±labilir modelleri listele
            available = list_available_models()
            if available:
                # Ä°lk 5 model adÄ±nÄ± gÃ¶ster
                clean_names = [m.replace('models/', '') for m in available[:5]]
                error_msg = (
                    f"HiÃ§bir model yÃ¼klenemedi. "
                    f"KullanÄ±labilir modeller: {', '.join(clean_names)}"
                )
            else:
                error_msg = "Model bulunamadÄ±. API anahtarÄ±nÄ±zÄ± kontrol edin."
            raise RuntimeError(error_msg)
    return _gemini_model


_groq_client = None


def get_groq_client():
    """Groq API client'Ä±nÄ± dÃ¶ndÃ¼rÃ¼r"""
    global _groq_client
    if not GROQ_AVAILABLE:
        raise RuntimeError("Groq paketi yÃ¼klÃ¼ deÄŸil. 'pip install groq' komutu ile yÃ¼kleyin.")
    if not GROQ_API_KEY:
        raise RuntimeError(
            "GROQ_API_KEY deÄŸerini .env dosyasÄ±na ekleyip uygulamayÄ± yeniden baÅŸlatÄ±n. "
            "Ãœcretsiz API anahtarÄ± iÃ§in: https://console.groq.com/"
        )
    if _groq_client is None:
        _groq_client = Groq(api_key=GROQ_API_KEY)
    return _groq_client


embedder = SentenceTransformer(EMBED_MODEL_NAME)
chroma_client = chromadb.Client(Settings(anonymized_telemetry=False))

active_collection = None
current_docs: Dict[str, Dict[str, str]] = {}

# Sohbet hafÄ±zasÄ± - Ã¶nceki mesajlarÄ± ve kullanÄ±cÄ± profilini tutar
conversation_history: List[Dict[str, str]] = []
user_profile: Dict[str, str] = {}


def normalize_text(text: str) -> str:
    cleaned = re.sub(r"\s+", " ", text or "").strip()
    return cleaned


def sanitize_question(q: str) -> str:
    blockers = ["ceza", "suÃ§", "yaptÄ±rÄ±m", "kovuÅŸturma", "kimlik", "tc", "disiplin"]
    for b in blockers:
        q = q.replace(b, f"{b} (mevzuat kapsamÄ±nda)")
    return q


def update_user_profile(message: str) -> None:
    """
    KullanÄ±cÄ±nÄ±n verdiÄŸi basit kiÅŸisel bilgileri (Ã¶r. ad, Ã¼ÅŸÃ¼rÃ¼m) profilde saklar.
    Bu bilgiler belgeye baÄŸlÄ± deÄŸildir ve belge iÃ§inde aranmaz.
    """
    global user_profile
    text = (message or "").strip()
    lower = text.lower()

    # Ad yakalama: "benim adÄ±m X", "adÄ±m X", "ismim X"
    name_patterns = [
        r"\bbenim ad[Ä±i]m\s+([A-Za-zÃ‡ÄÄ°Ã–ÅÃœÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+)",
        r"\bad[Ä±i]m\s+([A-Za-zÃ‡ÄÄ°Ã–ÅÃœÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+)",
        r"\bismim\s+([A-Za-zÃ‡ÄÄ°Ã–ÅÃœÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+)",
    ]
    import re as _re

    for pat in name_patterns:
        m = _re.search(pat, text, flags=_re.IGNORECASE)
        if m:
            name = m.group(1).strip()
            # Ä°lk harfi bÃ¼yÃ¼k yap, geri kalanÄ± olduÄŸu gibi bÄ±rak
            if name:
                user_profile["name"] = name[0].upper() + name[1:]
            break

    # ÃœÅŸÃ¼me / sÄ±caklÄ±k hassasiyeti
    if "Ã¼ÅŸÃ¼rÃ¼m" in lower or "Ã§ok Ã¼ÅŸÃ¼rÃ¼m" in lower:
        user_profile["cold_sensitivity"] = "high"


def is_weather_related_question(question: str) -> bool:
    """Soru hava durumu, aktivite veya kÄ±yafet Ã¶nerisi ile ilgili mi kontrol eder"""
    question_lower = question.lower()
    weather_keywords = [
        "hava durumu", "hava", "sÄ±caklÄ±k", "yaÄŸmur", "kar", "rÃ¼zgar", "nem",
        "aktivite Ã¶ner", "aktivite", "ne yapabilirim", "ne yapmalÄ±yÄ±m",
        "kÄ±yafet Ã¶ner", "kÄ±yafet", "giyin", "giyim", "nasÄ±l giyinmeliyim",
        "bugÃ¼nkÃ¼ hava", "ÅŸu anki hava", "gÃ¼ncel hava", "hava durumuna gÃ¶re",
        "havaya gÃ¶re", "iklim", "mevsim"
    ]
    return any(keyword in question_lower for keyword in weather_keywords)


def read_pdf(file_path: str) -> List[Tuple[int, str]]:
    try:
        reader = PdfReader(file_path)
        pages: List[Tuple[int, str]] = []
        for idx, page in enumerate(reader.pages, start=1):
            content = page.extract_text() or ""
            normalized = normalize_text(content)
            if normalized:
                pages.append((idx, normalized))
        return pages
    except Exception as e:
        raise RuntimeError(f"PDF okuma hatasÄ±: {str(e)}")


def read_txt(file_path: str) -> List[Tuple[int, str]]:
    try:
        with open(file_path, "r", encoding="utf-8", errors="ignore") as handle:
            content = handle.read()
        normalized = normalize_text(content)
        return [(1, normalized)] if normalized else []
    except Exception as e:
        raise RuntimeError(f"TXT okuma hatasÄ±: {str(e)}")


def chunk_pages(pages: List[Tuple[int, str]]) -> Tuple[List[str], List[Dict]]:
    chunks: List[str] = []
    metadatas: List[Dict] = []
    chunk_step = max(1, CHUNK_SIZE - CHUNK_OVERLAP)
    for page_num, text in pages:
        if not text:
            continue
        start = 0
        local_idx = 0
        while start < len(text):
            end = min(len(text), start + CHUNK_SIZE)
            chunk = text[start:end]
            chunks.append(chunk)
            metadatas.append(
                {
                    "page": page_num,
                    "chunk_id": f"P{page_num}-C{local_idx}",
                }
            )
            start += chunk_step
            local_idx += 1
    return chunks, metadatas


def reset_collection():
    global active_collection, current_docs
    try:
        chroma_client.delete_collection(COLLECTION_NAME)
    except Exception:
        # Koleksiyon yoksa veya baÅŸka bir "bulunamadÄ±" hatasÄ± gelirse gÃ¶z ardÄ± et
        pass
    active_collection = chroma_client.create_collection(name=COLLECTION_NAME)
    current_docs = {}


def ensure_collection():
    global active_collection
    if active_collection is None:
        try:
            active_collection = chroma_client.get_collection(COLLECTION_NAME)
        except (getattr(chroma_errors, "InvalidCollectionError", Exception),
                getattr(chroma_errors, "NotFoundError", Exception)):
            active_collection = chroma_client.create_collection(name=COLLECTION_NAME)


def ingest_file(file_obj):
    global current_docs
    if not file_obj:
        return "LÃ¼tfen PDF veya TXT dosyasÄ± yÃ¼kleyin."

    try:
        # Gradio file nesnesini handle et
        # Gradio file nesnesi genellikle .name attribute'una sahiptir
        if hasattr(file_obj, 'name'):
            file_path_str = file_obj.name
        elif isinstance(file_obj, (str, Path)):
            file_path_str = str(file_obj)
        else:
            # DiÄŸer durumlar iÃ§in string'e Ã§evir
            file_path_str = str(file_obj)
        
        file_path = Path(file_path_str)
        
        # Dosya yolunu kontrol et
        if not file_path.exists():
            return f"âŒ Hata: Dosya bulunamadÄ±: {file_path}"
        
        # Dosya boyutunu kontrol et
        file_size = file_path.stat().st_size
        if file_size == 0:
            return "âŒ Hata: Dosya boÅŸ."
        
        # Dosya uzantÄ±sÄ±nÄ± kontrol et
        suffix = file_path.suffix.lower()
        if suffix not in [".pdf", ".txt"]:
            return "âŒ Sadece PDF veya TXT destekleniyor."

        # DosyayÄ± oku
        if suffix == ".pdf":
            pages = read_pdf(str(file_path))
        else:  # .txt
            pages = read_txt(str(file_path))

        if not pages:
            return "âŒ Belgeden metin Ã§Ä±karÄ±lamadÄ±."
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        return f"âŒ Dosya okuma hatasÄ±: {str(e)}\n\nDetay: {error_detail[:200]}"

    ensure_collection()
    chunks, metadatas = chunk_pages(pages)
    # metadata'ya belge adÄ±nÄ± ekle
    for meta in metadatas:
        meta["doc"] = file_path.name

    embeddings = embedder.encode(chunks, batch_size=32, convert_to_numpy=True).tolist()

    ids = [str(uuid.uuid4()) for _ in chunks]
    active_collection.add(
        ids=ids,
        documents=chunks,
        embeddings=embeddings,
        metadatas=metadatas,
    )

    current_docs[file_path.name] = {
        "chunks": len(chunks),
        "path": str(file_path),
    }

    status = (
        f"âœ… {file_path.name} yÃ¼klendi. "
        f"{len(chunks)} parÃ§a koleksiyona eklendi."
    )
    return status


def retrieve_chunks(question: str, top_k: int = DEFAULT_TOP_K, use_mmr: bool = False):
    if active_collection is None:
        raise RuntimeError("Ã–nce bir belge yÃ¼kleyin.")

    query_vec = embedder.encode([question], convert_to_numpy=True).tolist()
    query_params = {
        "query_embeddings": query_vec,
        "n_results": top_k,
    }
    if use_mmr:
        query_params.update({"mmr": True, "lambda_mult": MMR_LAMBDA})

    try:
        results = active_collection.query(**query_params)
    except TypeError as err:
        # MMR parametresi desteklenmiyorsa klasik sorguya dÃ¼ÅŸ
        if use_mmr and "unexpected keyword argument 'mmr'" in str(err):
            query_params.pop("mmr", None)
            query_params.pop("lambda_mult", None)
            results = active_collection.query(**query_params)
        else:
            raise
    documents = results.get("documents", [[]])[0]
    metadatas = results.get("metadatas", [[]])[0]
    return documents, metadatas


def format_context(docs: List[str], metas: List[Dict]) -> str:
    paired = []
    for doc, meta in zip(docs, metas):
        doc_label = meta.get("doc", "Belge")
        page_num = meta.get('page', '?')
        chunk_id = meta.get('chunk_id', '?')
        tag = f"ğŸ“„ BELGE: {doc_label} | Sayfa: {page_num} | ParÃ§a: {chunk_id}"
        paired.append(f"[{tag}]\n{doc}")
    return "\n\n---\n\n".join(paired)


def build_sources(metas: List[Dict]) -> List[str]:
    unique = []
    seen = set()
    for meta in metas:
        doc_name = meta.get('doc', 'Belge')
        page_num = meta.get('page', '?')
        chunk_id = meta.get('chunk_id', '?')
        # Belge bazÄ±nda grupla
        label = f"ğŸ“„ {doc_name} | Sayfa {page_num} | ParÃ§a {chunk_id}"
        if label not in seen:
            seen.add(label)
            unique.append(label)
    return unique


def get_weather_summary(city: str) -> Tuple[bool, str, str]:
    """
    OpenWeatherMap'ten hava durumu Ã¶zetini dÃ¶ndÃ¼rÃ¼r.

    Returns:
        has_weather (bool): GerÃ§ek API verisi baÅŸarÄ±yla alÄ±ndÄ± mÄ±?
        normalized_city (str): KullanÄ±lan ÅŸehir adÄ±
        summary (str): KÄ±sa TÃ¼rkÃ§e Ã¶zet veya hata bilgisi
    """
    city = (city or "").strip() or DEFAULT_CITY

    # API anahtarÄ± yoksa akÄ±ÅŸ bozulmasÄ±n, sadece belgeye dayanÄ±lacaÄŸÄ±nÄ± sÃ¶yle
    if not WEATHER_API_KEY:
        return (
            False,
            city,
            "Hava durumu API anahtarÄ± bulunamadÄ±. LÃ¼tfen cevabÄ±nÄ± sadece belge baÄŸlamÄ±na dayandÄ±r.",
        )

    try:
        params = {
            "q": city,
            "appid": WEATHER_API_KEY,
            "units": "metric",
            "lang": "tr",
        }
        resp = requests.get(
            "https://api.openweathermap.org/data/2.5/weather",
            params=params,
            timeout=8,
        )
        if resp.status_code != 200:
            return (
                False,
                city,
                "Hava durumu ÅŸu anda alÄ±namÄ±yor. LÃ¼tfen cevabÄ±nÄ± sadece belge baÄŸlamÄ±na dayandÄ±r.",
            )

        data = resp.json()
        weather_list = data.get("weather") or []
        main = data.get("main") or {}
        wind = data.get("wind") or {}

        description = (
            weather_list[0].get("description", "").capitalize()
            if weather_list
            else ""
        )
        temp = main.get("temp")
        feels = main.get("feels_like")
        humidity = main.get("humidity")
        wind_speed = wind.get("speed")

        parts = []
        if description:
            parts.append(description)
        if temp is not None:
            parts.append(f"SÄ±caklÄ±k: {temp:.1f}Â°C")
        if feels is not None:
            parts.append(f"Hissedilen: {feels:.1f}Â°C")
        if humidity is not None:
            parts.append(f"Nem: %{humidity}")
        if wind_speed is not None:
            parts.append(f"RÃ¼zgar: {wind_speed:.1f} m/sn")

        if not parts:
            return (
                False,
                city,
                "Hava durumu verisi alÄ±namadÄ±. LÃ¼tfen cevabÄ±nÄ± sadece belge baÄŸlamÄ±na dayandÄ±r.",
            )

        summary = f"{city} iÃ§in gÃ¼ncel hava durumu: " + ", ".join(parts) + "."
        return True, city, summary
    except Exception:
        # Her tÃ¼rlÃ¼ hata durumunda sadece belgeye dayanÄ±lmasÄ±nÄ± saÄŸla
        return (
            False,
            city,
            "Hava durumu servisine ulaÅŸÄ±lamadÄ±. LÃ¼tfen cevabÄ±nÄ± sadece belge baÄŸlamÄ±na dayandÄ±r.",
        )


def format_conversation_history(history: List[Dict[str, str]], max_turns: int = 5) -> str:
    """Sohbet geÃ§miÅŸini prompt formatÄ±na Ã§evirir (son N mesaj)"""
    if not history:
        return ""
    
    # Son N mesajÄ± al (Ã§ok uzun olmasÄ±n)
    recent_history = history[-max_turns:] if len(history) > max_turns else history
    
    formatted = []
    for msg in recent_history:
        role = msg.get("role", "")
        content = msg.get("content", "")
        if role == "user":
            formatted.append(f"KullanÄ±cÄ±: {content}")
        elif role == "assistant":
            formatted.append(f"Asistan: {content}")
    
    if formatted:
        return "\n".join(formatted)
    return ""


def format_user_profile(profile: Dict[str, str]) -> str:
    """KullanÄ±cÄ± profilini (ad, Ã¼ÅŸÃ¼me vb.) prompt iÃ§in okunur hale getirir."""
    if not profile:
        return ""
    parts = []
    name = profile.get("name")
    if name:
        parts.append(f"KullanÄ±cÄ±nÄ±n adÄ±: {name}")
    cold = profile.get("cold_sensitivity")
    if cold == "high":
        parts.append("KullanÄ±cÄ± soÄŸuÄŸa karÅŸÄ± hassastÄ±r ve Ã§abuk Ã¼ÅŸÃ¼r.")
    if not parts:
        return ""
    return "\n".join(parts)


def call_gemini(
    context: str,
    question: str,
    sources: List[str],
    weather_summary: str,
    city: str,
    has_weather: bool,
    is_weather_question: bool = False,
    conversation_history: List[Dict[str, str]] = None,
    profile: Dict[str, str] | None = None,
) -> str:
    model = get_gemini_model()
    doc_list = ", ".join(sorted(current_docs.keys())) if current_docs else "Belge"

    weather_block = f"Hava durumu Ã¶zeti (ÅŸehir: {city}):\n{weather_summary}\n"

    # KullanÄ±cÄ± profilini formatla (ad, Ã¼ÅŸÃ¼me vb.)
    profile_text = ""
    if profile:
        profile_str = format_user_profile(profile)
        if profile_str:
            profile_text = (
                "\n\nKULLANICI PROFÄ°LÄ° (belgeden baÄŸÄ±msÄ±z, sohbetten Ã¶ÄŸrenilen):\n"
                f"{profile_str}\n\n"
                "Ã–NEMLÄ°:\n"
                "- Bu bilgiler belge iÃ§inde aranmaz; doÄŸrudan doÄŸru kabul edilir.\n"
                "- KullanÄ±cÄ± kendi adÄ±nÄ± veya Ã¶zelliklerini sÃ¶ylediyse, bunlarÄ± belge yerine sohbet geÃ§miÅŸine gÃ¶re kullan.\n"
            )

    # Ã–nceki sohbet geÃ§miÅŸini formatla
    history_text = ""
    if conversation_history:
        history_text = format_conversation_history(conversation_history, max_turns=5)
        if history_text:
            history_text = f"\n\nÃ–NCEKÄ° SOHBET GEÃ‡MÄ°ÅÄ° (baÄŸlam iÃ§in):\n{history_text}\n\nÃ–NEMLÄ°: YukarÄ±daki Ã¶nceki mesajlarÄ± dikkate al ve kullanÄ±cÄ±nÄ±n Ã¶nceki sÃ¶ylediklerini hatÄ±rla. Ã–rneÄŸin kullanÄ±cÄ± 'Ã¼ÅŸÃ¼rÃ¼m' dediyse, kÄ±yafet Ã¶nerirken daha sÄ±cak tutan kÄ±yafetler Ã¶ner."

    # Hava durumu sorularÄ± iÃ§in Ã¶zel kurallar
    if is_weather_question and has_weather:
        weather_rules = """
Ã–NEMLÄ° - Hava Durumu Sorusu:
- Bu soru hava durumu, aktivite veya kÄ±yafet Ã¶nerisi ile ilgilidir.
- Belge baÄŸlamÄ±nda hava durumu bilgisi olmasa bile, hava durumu API'sinden gelen bilgiyi kullanabilirsin.
- Hava durumu API'sinden gelen bilgi (sÄ±caklÄ±k, yaÄŸÄ±ÅŸ, rÃ¼zgar, nem vb.) baÄŸÄ±msÄ±z bir kaynaktÄ±r ve PDF'te olmasa bile kullanÄ±labilir.
- Belge baÄŸlamÄ±nda hava durumu ile ilgili bilgi yoksa, sadece hava durumu API bilgisine dayanarak pratik tavsiyeler ver.
- Ã–rnek: "Hava soÄŸuk, kalÄ±n giyin" veya "YaÄŸmur bekleniyor, yanÄ±nÄ±za ÅŸemsiye alÄ±n" gibi direkt hava durumuna gÃ¶re tavsiyeler verebilirsin.
"""
    else:
        weather_rules = """
- Belge baÄŸlamÄ±nda olmayan bir bilgiyi "Bu bilgi belgede yer almÄ±yor." diyerek aÃ§Ä±kÃ§a belirt.
- Hava durumu bilgisi yoksa veya alÄ±namadÄ±ysa cevabÄ±nÄ± sadece belge baÄŸlamÄ±na dayandÄ±r.
"""

    prompt = f"""
Sen bir akademik belge analiz ve tavsiye asistanÄ±sÄ±n.

KAYNAKLAR:
1) Belge baÄŸlamÄ± (PDF/TXT iÃ§eriÄŸi)
2) Hava durumu Ã¶zeti (varsa)
3) Sohbet geÃ§miÅŸi ve kullanÄ±cÄ± profili (kullanÄ±cÄ±nÄ±n kendisiyle ilgili verdiÄŸi bilgiler: ad, Ã¼ÅŸÃ¼me vb.)

Kurallar:
{weather_rules}
- KullanÄ±cÄ±nÄ±n kendisiyle ilgili verdiÄŸi kiÅŸisel bilgiler (ad, "Ã¼ÅŸÃ¼rÃ¼m" gibi ifadeler) iÃ§in bu bilgileri sohbet geÃ§miÅŸi / kullanÄ±cÄ± profilinden kullan; bu bilgiler iÃ§in belgede geÃ§me ÅŸartÄ± YOKTUR.
- Belge iÃ§eriÄŸiyle ilgili sorularda, sadece belge baÄŸlamÄ±na dayan ve baÄŸlamda yoksa "Bu bilgi belgede yer almÄ±yor." de.
- Hava durumu bilgisi varsa ve soruda hava durumu ile ilgili bir istek varsa, cevabÄ±nda hem belge kurallarÄ±na hem de hava durumu Ã¶zetine dayanarak kÄ±sa, pratik bir tavsiye Ã¼ret.
- Tahmin, uydurma veya belge/hava durumu/kullanÄ±cÄ± bilgisi dÄ±ÅŸÄ±nda yorum yapma.

Ã–NEMLÄ°: Her bilginin hangi kaynaktan geldiÄŸini mutlaka belirt!
- Belge iÃ§in: [Kaynak: belge_adÄ±.pdf, Sayfa X]
- Hava durumu iÃ§in: [Kaynak: Hava durumu API, Åehir: {city}]
- KullanÄ±cÄ± profili veya sohbet geÃ§miÅŸi iÃ§in: [Kaynak: KullanÄ±cÄ± profili / Sohbet geÃ§miÅŸi]

YanÄ±t formatÄ±:
SonuÃ§: <tek cÃ¼mlelik Ã¶zet> [Kaynak: ...]

GerekÃ§e:
- madde 1 [Kaynak: ...]
- madde 2 [Kaynak: ...]
- madde 3 [Kaynak: ...]

Akademik, tarafsÄ±z ve bilgilendirici ol.
- Her bilgi parÃ§asÄ±ndan sonra hangi belgeden, hava durumundan veya kullanÄ±cÄ± profilinden geldiÄŸini kÃ¶ÅŸeli parantez iÃ§inde belirt.
- Birden fazla belge veya kaynak kullanÄ±yorsan, her birini ayrÄ± ayrÄ± belirt.

Mevcut Belgeler: {doc_list}

Belge BaÄŸlamÄ± (her parÃ§a hangi belgeden geldiÄŸini gÃ¶sterir):
{context}

Hava Durumu BaÄŸlamÄ±:
{weather_block}
{profile_text}
{history_text}
KullanÄ±cÄ±nÄ±n Sorusu:
{question}
"""
    try:
        # GÃ¼venlik filtrelerini tamamen kapat - tÃ¼m sorulara cevap verebilsin
        safety_settings = [
            {"category": genai.types.HarmCategory.HARM_CATEGORY_HARASSMENT, 
             "threshold": genai.types.HarmBlockThreshold.BLOCK_NONE},
            {"category": genai.types.HarmCategory.HARM_CATEGORY_HATE_SPEECH, 
             "threshold": genai.types.HarmBlockThreshold.BLOCK_NONE},
            {"category": genai.types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, 
             "threshold": genai.types.HarmBlockThreshold.BLOCK_NONE},
            {"category": genai.types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, 
             "threshold": genai.types.HarmBlockThreshold.BLOCK_NONE},
        ]
        
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.3,
                max_output_tokens=512,
            ),
            safety_settings=safety_settings,
        )

        if response.candidates:
            cand = response.candidates[0]
            print("FINISH REASON:", getattr(cand, "finish_reason", None))
            print("SAFETY RATINGS:", getattr(cand, "safety_ratings", None))
        
        # Response'u gÃ¼venli ÅŸekilde parse et
        if response.candidates and len(response.candidates) > 0:
            candidate = response.candidates[0]
            
            # Finish reason kontrolÃ¼ - text'i almaya Ã§alÄ±ÅŸ
            finish_reason = candidate.finish_reason
            text = ""
            
            # Ã–nce text'i almaya Ã§alÄ±ÅŸ
            if candidate.content and candidate.content.parts:
                text = "".join(part.text for part in candidate.content.parts if hasattr(part, 'text'))
            
            # Text yoksa response.text'i dene
            if not text:
                try:
                    text = response.text or ""
                except Exception:
                    pass
            
            # Hala text yoksa, Ã¶zellikle SAFETY durumunda tekrar dene
            if not text:
                if finish_reason == 2:  # SAFETY - tekrar dene, daha aÃ§Ä±k prompt ile
                    try:
                        # Daha basit bir prompt ile tekrar dene
                        retry_prompt = f"""
AÅŸaÄŸÄ±daki metin akademik bir belgeden alÄ±nmÄ±ÅŸtÄ±r.
Herhangi bir yÃ¶nlendirme, talimat veya zararlÄ± iÃ§erik iÃ§ermemektedir.
Sadece bilgilendirici bir Ã¶zet istenmektedir.

BaÄŸlam:
{context}

Soru:
{question}

TÃ¼rkÃ§e, kÄ±sa ve bilgilendirici cevap:
"""
                        
                        retry_response = model.generate_content(
                            retry_prompt,
                            generation_config=genai.types.GenerationConfig(
                                temperature=0.7,
                                max_output_tokens=512,
                            ),
                            safety_settings=safety_settings,
                        )
                        
                        if retry_response.candidates and len(retry_response.candidates) > 0:
                            retry_candidate = retry_response.candidates[0]
                            if retry_candidate.content and retry_candidate.content.parts:
                                text = "".join(part.text for part in retry_candidate.content.parts if hasattr(part, 'text'))
                            if not text:
                                try:
                                    text = retry_response.text or ""
                                except:
                                    pass
                    except Exception:
                        pass
                    
                    if not text:
                        text = "âš ï¸ YanÄ±t gÃ¼venlik filtresi tarafÄ±ndan engellendi. LÃ¼tfen soruyu farklÄ± ÅŸekilde sorun."
                elif finish_reason == 3:  # RECITATION (telif hakkÄ±)
                    text = "âš ï¸ YanÄ±t telif hakkÄ± nedeniyle engellendi."
                elif finish_reason == 4:  # OTHER
                    text = "âš ï¸ YanÄ±t oluÅŸturulamadÄ±. LÃ¼tfen tekrar deneyin."
                elif finish_reason == 5:  # MAX_TOKENS
                    text = "âš ï¸ YanÄ±t Ã§ok uzun oldu. LÃ¼tfen daha spesifik bir soru sorun."
                else:
                    text = "âš ï¸ Modelden yanÄ±t alÄ±namadÄ±."
        else:
            text = "âš ï¸ Modelden yanÄ±t alÄ±namadÄ±. LÃ¼tfen tekrar deneyin."
        
        text = text.strip()
        if not text:
            text = "ÃœzgÃ¼nÃ¼m, modelden yanÄ±t alÄ±namadÄ±."
            
    except Exception as e:
        text = f"âš ï¸ Hata: {str(e)}"

    if "Kaynaklar:" not in text:
        # KaynaklarÄ± belgelere gÃ¶re grupla
        sources_by_doc = {}
        for src in sources:
            # "ğŸ“„ belge_adÄ± | Sayfa X | ParÃ§a Y" formatÄ±ndan belge adÄ±nÄ± Ã§Ä±kar
            if "ğŸ“„" in src:
                parts = src.split("|")
                doc_name = parts[0].replace("ğŸ“„", "").strip()
                page_info = parts[1].strip() if len(parts) > 1 else ""
                chunk_info = parts[2].strip() if len(parts) > 2 else ""
            else:
                doc_name = "Bilinmeyen"
                page_info = src
            
            if doc_name not in sources_by_doc:
                sources_by_doc[doc_name] = []
            sources_by_doc[doc_name].append(f"{page_info} {chunk_info}".strip())
        
        formatted_sources = []
        for doc_name in sorted(sources_by_doc.keys()):
            formatted_sources.append(f"\nğŸ“„ {doc_name}:")
            for page_info in sources_by_doc[doc_name]:
                formatted_sources.append(f"  â€¢ {page_info}")
        
        text = f"{text.strip()}\n\nğŸ“š Kaynaklar (Belge):{''.join(formatted_sources)}"

        # Hava durumu kaynaÄŸÄ±nÄ± da ekle
        if has_weather:
            text = f"{text}\n\nğŸŒ¤ Hava Durumu KaynaÄŸÄ±:\n  â€¢ OpenWeatherMap API (Åehir: {city})"

    return text


def call_groq(
    context: str,
    question: str,
    sources: List[str],
    weather_summary: str,
    city: str,
    has_weather: bool,
    is_weather_question: bool = False,
    conversation_history: List[Dict[str, str]] = None,
    profile: Dict[str, str] | None = None,
) -> str:
    """Groq API kullanarak LLM Ã§aÄŸrÄ±sÄ± yapar (gÃ¼venlik filtreleri yok, Ã§ok hÄ±zlÄ±)"""
    try:
        client = get_groq_client()
        doc_list = ", ".join(sorted(current_docs.keys())) if current_docs else "Belge"

        weather_block = f"Hava durumu Ã¶zeti (ÅŸehir: {city}):\n{weather_summary}\n"

        # KullanÄ±cÄ± profilini formatla (ad, Ã¼ÅŸÃ¼me vb.)
        profile_text = ""
        if profile:
            profile_str = format_user_profile(profile)
            if profile_str:
                profile_text = (
                    "\n\nKULLANICI PROFÄ°LÄ° (belgeden baÄŸÄ±msÄ±z, sohbetten Ã¶ÄŸrenilen):\n"
                    f"{profile_str}\n\n"
                    "Ã–NEMLÄ°:\n"
                    "- Bu bilgiler belge iÃ§inde aranmaz; doÄŸrudan doÄŸru kabul edilir.\n"
                    "- KullanÄ±cÄ± kendi adÄ±nÄ± veya Ã¶zelliklerini sÃ¶ylediyse, bunlarÄ± belge yerine sohbet geÃ§miÅŸine gÃ¶re kullan.\n"
                )

        # Ã–nceki sohbet geÃ§miÅŸini formatla
        history_text = ""
        if conversation_history:
            history_text = format_conversation_history(conversation_history, max_turns=5)
            if history_text:
                history_text = f"\n\nÃ–NCEKÄ° SOHBET GEÃ‡MÄ°ÅÄ° (baÄŸlam iÃ§in):\n{history_text}\n\nÃ–NEMLÄ°: YukarÄ±daki Ã¶nceki mesajlarÄ± dikkate al ve kullanÄ±cÄ±nÄ±n Ã¶nceki sÃ¶ylediklerini hatÄ±rla. Ã–rneÄŸin kullanÄ±cÄ± 'Ã¼ÅŸÃ¼rÃ¼m' dediyse, kÄ±yafet Ã¶nerirken daha sÄ±cak tutan kÄ±yafetler Ã¶ner."

        # Hava durumu sorularÄ± iÃ§in Ã¶zel kurallar
        if is_weather_question and has_weather:
            weather_rules = """
Ã–NEMLÄ° - Hava Durumu Sorusu:
- Bu soru hava durumu, aktivite veya kÄ±yafet Ã¶nerisi ile ilgilidir.
- Belge baÄŸlamÄ±nda hava durumu bilgisi olmasa bile, hava durumu API'sinden gelen bilgiyi kullanabilirsin.
- Hava durumu API'sinden gelen bilgi (sÄ±caklÄ±k, yaÄŸÄ±ÅŸ, rÃ¼zgar, nem vb.) baÄŸÄ±msÄ±z bir kaynaktÄ±r ve PDF'te olmasa bile kullanÄ±labilir.
- Belge baÄŸlamÄ±nda hava durumu ile ilgili bilgi yoksa, sadece hava durumu API bilgisine dayanarak pratik tavsiyeler ver.
- Ã–rnek: "Hava soÄŸuk, kalÄ±n giyin" veya "YaÄŸmur bekleniyor, yanÄ±nÄ±za ÅŸemsiye alÄ±n" gibi direkt hava durumuna gÃ¶re tavsiyeler verebilirsin.
"""
        else:
            weather_rules = """
- Belge baÄŸlamÄ±nda olmayan bir bilgiyi "Bu bilgi belgede yer almÄ±yor." diyerek aÃ§Ä±kÃ§a belirt.
- Hava durumu bilgisi yoksa veya alÄ±namadÄ±ysa cevabÄ±nÄ± sadece belge baÄŸlamÄ±na dayandÄ±r.
"""

        prompt = f"""Sen bir akademik belge analiz ve tavsiye asistanÄ±sÄ±n.

KAYNAKLAR:
1) Belge baÄŸlamÄ± (PDF/TXT iÃ§eriÄŸi)
2) Hava durumu Ã¶zeti (varsa)
3) Sohbet geÃ§miÅŸi ve kullanÄ±cÄ± profili (kullanÄ±cÄ±nÄ±n kendisiyle ilgili verdiÄŸi bilgiler: ad, Ã¼ÅŸÃ¼rÃ¼m vb.)

Kurallar:
{weather_rules}
- KullanÄ±cÄ±nÄ±n kendisiyle ilgili verdiÄŸi kiÅŸisel bilgiler (ad, "Ã¼ÅŸÃ¼rÃ¼m" gibi ifadeler) iÃ§in bu bilgileri sohbet geÃ§miÅŸi / kullanÄ±cÄ± profilinden kullan; bu bilgiler iÃ§in belgede geÃ§me ÅŸartÄ± YOKTUR.
- Belge iÃ§eriÄŸiyle ilgili sorularda, sadece belge baÄŸlamÄ±na dayan ve baÄŸlamda yoksa "Bu bilgi belgede yer almÄ±yor." de.
- Hava durumu bilgisi varsa ve soruda hava durumu ile ilgili bir istek varsa, cevabÄ±nda hem belge kurallarÄ±na hem de hava durumu Ã¶zetine dayanarak kÄ±sa, pratik bir tavsiye Ã¼ret.
- Tahmin, uydurma veya belge/hava durumu/kullanÄ±cÄ± bilgisi dÄ±ÅŸÄ±nda yorum yapma.

Ã–NEMLÄ°: Her bilginin hangi kaynaktan geldiÄŸini mutlaka belirt!
- Belge iÃ§in: [Kaynak: belge_adÄ±.pdf, Sayfa X]
- Hava durumu iÃ§in: [Kaynak: Hava durumu API, Åehir: {city}]
- KullanÄ±cÄ± profili veya sohbet geÃ§miÅŸi iÃ§in: [Kaynak: KullanÄ±cÄ± profili / Sohbet geÃ§miÅŸi]

YanÄ±t formatÄ±:
SonuÃ§: <tek cÃ¼mlelik Ã¶zet> [Kaynak: ...]

GerekÃ§e:
- madde 1 [Kaynak: ...]
- madde 2 [Kaynak: ...]
- madde 3 [Kaynak: ...]

Akademik, tarafsÄ±z ve bilgilendirici ol.
- Her bilgi parÃ§asÄ±ndan sonra hangi belgeden, hava durumundan veya kullanÄ±cÄ± profilinden geldiÄŸini kÃ¶ÅŸeli parantez iÃ§inde belirt.
- Birden fazla belge veya kaynak kullanÄ±yorsan, her birini ayrÄ± ayrÄ± belirt.

Mevcut Belgeler: {doc_list}

Belge BaÄŸlamÄ± (her parÃ§a hangi belgeden geldiÄŸini gÃ¶sterir):
{context}

Hava Durumu BaÄŸlamÄ±:
{weather_block}
{profile_text}
{history_text}

KullanÄ±cÄ±nÄ±n Sorusu:
{question}
"""

        # Groq API Ã§aÄŸrÄ±sÄ± - GÃ¼ncel model listesi (eski model kullanÄ±mdan kaldÄ±rÄ±ldÄ±)
        # Model adaylarÄ±: Ã¶nce en gÃ¼Ã§lÃ¼ olanÄ± dene
        model_candidates = [
            "llama-3.3-70b-versatile",      # Yeni versiyon (Ã¶nerilen)
            "llama-3.1-70b-versatile",      # Eski (fallback)
            "llama-3.1-8b-instant",         # Daha hÄ±zlÄ± ama kÃ¼Ã§Ã¼k
            "mixtral-8x7b-32768",           # Uzun baÄŸlam
            "gemma2-9b-it",                 # Google'Ä±n modeli
        ]
        
        chat_completion = None
        last_error = None
        
        for model_name in model_candidates:
            try:
                chat_completion = client.chat.completions.create(
                    messages=[
                        {
                            "role": "system",
                            "content": "Sen TÃ¼rkÃ§e konuÅŸan, akademik belge analiz ve tavsiye konusunda uzman bir asistansÄ±n. Her zaman kaynak belirtmeyi unutma."
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    model=model_name,
                    temperature=0.3,
                    max_tokens=1024,
                )
                # BaÅŸarÄ±lÄ± oldu, dÃ¶ngÃ¼den Ã§Ä±k
                break
            except Exception as e:
                last_error = e
                # Bu model Ã§alÄ±ÅŸmadÄ±, bir sonrakini dene
                continue
        
        if chat_completion is None:
            raise RuntimeError(f"HiÃ§bir Groq modeli Ã§alÄ±ÅŸmadÄ±. Son hata: {last_error}")

        text = chat_completion.choices[0].message.content.strip()

        if not text:
            text = "ÃœzgÃ¼nÃ¼m, modelden yanÄ±t alÄ±namadÄ±."

    except Exception as e:
        text = f"âš ï¸ Groq API HatasÄ±: {str(e)}"

    # KaynaklarÄ± ekle (aynÄ± format)
    if "Kaynaklar:" not in text and sources:
        sources_by_doc = {}
        for src in sources:
            if "ğŸ“„" in src:
                parts = src.split("|")
                doc_name = parts[0].replace("ğŸ“„", "").strip()
                page_info = parts[1].strip() if len(parts) > 1 else ""
                chunk_info = parts[2].strip() if len(parts) > 2 else ""
            else:
                doc_name = "Bilinmeyen"
                page_info = src
            
            if doc_name not in sources_by_doc:
                sources_by_doc[doc_name] = []
            sources_by_doc[doc_name].append(f"{page_info} {chunk_info}".strip())
        
        formatted_sources = []
        for doc_name in sorted(sources_by_doc.keys()):
            formatted_sources.append(f"\nğŸ“„ {doc_name}:")
            for page_info in sources_by_doc[doc_name]:
                formatted_sources.append(f"  â€¢ {page_info}")
        
        text = f"{text.strip()}\n\nğŸ“š Kaynaklar (Belge):{''.join(formatted_sources)}"

    # Hava durumu kaynaÄŸÄ±nÄ± da ekle
    if has_weather:
        text = f"{text}\n\nğŸŒ¤ Hava Durumu KaynaÄŸÄ±:\n  â€¢ OpenWeatherMap API (Åehir: {city})"

    return text


def answer_question(message, city, history, top_k, use_mmr, model_choice):
    global conversation_history, user_profile
    history = history or []
    if not message:
        return history, history, ""

    if active_collection is None:
        reply = "Ã–nce bir PDF/TXT yÃ¼kleyip indeks oluÅŸturmalÄ±sÄ±n."
        history.append({"role": "user", "content": message})
        history.append({"role": "assistant", "content": reply})
        # HafÄ±zaya da ekle
        conversation_history.append({"role": "user", "content": message})
        conversation_history.append({"role": "assistant", "content": reply})
        return history, history, ""

    try:
        # Ã–nce kullanÄ±cÄ± profilini gÃ¼ncelle (ad, Ã¼ÅŸÃ¼me vb.)
        update_user_profile(message)

        message = sanitize_question(message)
        # Åehri hazÄ±rla (boÅŸsa varsayÄ±lan ElazÄ±ÄŸ kullanÄ±lÄ±r)
        city = (city or "").strip() or DEFAULT_CITY

        # Hava durumunu al (gerÃ§ek API veya gÃ¼venli fallback)
        has_weather, normalized_city, weather_summary = get_weather_summary(city)

        # Sorunun hava durumu ile ilgili olup olmadÄ±ÄŸÄ±nÄ± kontrol et
        is_weather_question = is_weather_related_question(message)

        # Ã–nce belge baÄŸlamÄ±nÄ± getir
        documents, metadatas = retrieve_chunks(
            message, top_k=int(top_k), use_mmr=bool(use_mmr)
        )
        
        # Model seÃ§imine gÃ¶re Ã§aÄŸrÄ± fonksiyonunu belirle
        if model_choice == "Groq (Ã–nerilen - GÃ¼venlik Filtresi Yok)":
            call_llm = call_groq
        else:
            call_llm = call_gemini

        # Hava durumu sorularÄ±nda belge baÄŸlamÄ± bulunamasa bile devam et
        if not documents:
            if is_weather_question and has_weather:
                # Hava durumu sorusu ve API'den veri var, sadece hava durumuna gÃ¶re cevap ver
                context = "Belge baÄŸlamÄ± bulunamadÄ±, ancak hava durumu bilgisi mevcut."
                sources = []
                reply = call_llm(
                    context=context,
                    question=message,
                    sources=sources,
                    weather_summary=weather_summary,
                    city=normalized_city,
                    has_weather=has_weather,
                    is_weather_question=True,
                    conversation_history=conversation_history,
                    profile=user_profile,
                )
            else:
                reply = "BaÄŸlam bulunamadÄ±. Daha farklÄ± bir soru deneyebilirsin."
        else:
            raw_context = format_context(documents, metadatas)

            context = f"""
Bu iÃ§erik tamamen akademik ve bilgilendirme amaÃ§lÄ±dÄ±r.
GerÃ§ek kiÅŸi, suÃ§ veya suistimal iÃ§ermemektedir.

{raw_context}
"""

            sources = build_sources(metadatas)
            reply = call_llm(
                context=context,
                question=message,
                sources=sources,
                weather_summary=weather_summary,
                city=normalized_city,
                has_weather=has_weather,
                is_weather_question=is_weather_question,
                conversation_history=conversation_history,
                profile=user_profile,
            )
    except Exception as exc:
        reply = f"Hata: {exc}"

    # Hem Gradio history'ye hem de global conversation_history'ye ekle
    history.append({"role": "user", "content": message})
    history.append({"role": "assistant", "content": reply})
    conversation_history.append({"role": "user", "content": message})
    conversation_history.append({"role": "assistant", "content": reply})
    
    # HafÄ±zayÄ± Ã§ok uzamasÄ±n diye sÄ±nÄ±rla (son 20 mesaj)
    if len(conversation_history) > 20:
        conversation_history = conversation_history[-20:]
    
    return history, history, ""


def handle_upload(file_objs, history):
    history = history or []
    files = file_objs if isinstance(file_objs, list) else [file_objs]
    files = [f for f in files if f]
    if not files:
        return history, history, "LÃ¼tfen en az bir dosya seÃ§in."

    statuses = []
    for file_obj in files:
        status = ingest_file(file_obj)
        statuses.append(status)

    doc_list = ", ".join(sorted(current_docs.keys())) or "-"
    summary = "\n".join(statuses)
    summary += f"\nğŸ“š Toplam belge: {len(current_docs)} ({doc_list})"

    return history, history, summary


def clear_chat():
    """Sohbet geÃ§miÅŸini temizler (hem UI hem hafÄ±za)"""
    global conversation_history
    conversation_history = []
    return [], [], ""


def clear_documents(history):
    reset_collection()
    history = history or []
    return history, history, "ğŸ“ Koleksiyon temizlendi. Yeni belgeler yÃ¼kleyin."


with gr.Blocks(title="Mini RAG - Mevzuat") as demo:
    gr.Markdown(
        """
        # ğŸ“š Mini RAG - Mevzuat AsistanÄ±
        Tek bir PDF/TXT yÃ¼kle, belgede geÃ§en kural ve baÅŸlÄ±klarÄ± anÄ±nda sor.
        """
    )

    chatbot = gr.Chatbot(label="Sohbet", height=420)
    status_box = gr.Markdown("ğŸ”„ Ã–nce belge yÃ¼kleyin.")
    history_state = gr.State([])

    with gr.Row():
        file_input = gr.File(
            label="PDF veya TXT yÃ¼kle",
            file_types=[".pdf", ".txt"],
            file_count="multiple",
        )
        clear_btn = gr.Button("Sohbeti temizle", variant="secondary")
        clear_docs_btn = gr.Button("Belgeleri temizle", variant="stop")

    # Model seÃ§enekleri
    model_choices = ["Gemini (Google)"]
    if GROQ_AVAILABLE and GROQ_API_KEY:
        model_choices.insert(0, "Groq (Ã–nerilen - GÃ¼venlik Filtresi Yok)")
    
    with gr.Row():
        top_k_slider = gr.Slider(
            minimum=3,
            maximum=6,
            step=1,
            value=DEFAULT_TOP_K,
            label="Top K (kaÃ§ parÃ§a getirilsin?)",
        )
        mmr_checkbox = gr.Checkbox(
            label="MMR ile Ã§eÅŸitliliÄŸi artÄ±r",
            value=False,
            info="Benzerlik + Ã§eÅŸitlilik dengesi saÄŸlar",
        )
        model_choice = gr.Dropdown(
            label="LLM Modeli",
            choices=model_choices,
            value=model_choices[0],
            info="Groq: GÃ¼venlik filtresi yok, hÄ±zlÄ±. Gemini: Google'Ä±n modeli (bazen filtreler)",
        )

    with gr.Row():
        question_box = gr.Textbox(
            label="Sorunuzu yazÄ±n",
            placeholder="Ã–rn. 'Belgede gizlilik kuralÄ± ne?' veya 'BugÃ¼nkÃ¼ hava durumuna gÃ¶re ne Ã¶nerirsin?'",
            scale=3,
        )
        city_box = gr.Dropdown(
            label="Åehir (hava durumu iÃ§in)",
            choices=TURKIYE_SEHIRLERI,
            value=DEFAULT_CITY,
            allow_custom_value=True,
            scale=1,
            info="TÃ¼rkiye'nin 81 ÅŸehrinden birini seÃ§in veya yazÄ±n",
        )

    file_input.upload(
        fn=handle_upload,
        inputs=[file_input, history_state],
        outputs=[chatbot, history_state, status_box],
    )

    question_box.submit(
        fn=answer_question,
        inputs=[question_box, city_box, history_state, top_k_slider, mmr_checkbox, model_choice],
        outputs=[chatbot, history_state, question_box],
    )

    clear_btn.click(
        fn=clear_chat,
        inputs=None,
        outputs=[chatbot, history_state, question_box],
    )

    clear_docs_btn.click(
        fn=clear_documents,
        inputs=[history_state],
        outputs=[chatbot, history_state, status_box],
    )

    gr.Markdown(
        "Cevaplar her zaman 'BaÄŸlamda yoksa uydurma yok' ilkesine gÃ¶re Ã¼retilir."
    )


if __name__ == "__main__":
    demo.launch()

